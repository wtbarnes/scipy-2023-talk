{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b55ea1-f2f9-4a53-acb1-bef03184d541",
   "metadata": {},
   "source": [
    "# Using SunPy in the Cloud: Scalable Solar Data Analysis with `sunpy`, `astropy`, and `dask`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c901b1-1e3c-4d93-b1ac-c836178de69b",
   "metadata": {},
   "source": [
    "The goal of this notebook is demonstrate how to analyze solar image data.\n",
    "The Atomospheric Imaging Assembly (AIA) on the Solar Dynamics Observatory (SDO) takes an image of the entire Sun at several extreme ultraviolet (EUV) wavelengths every 12 seconds.\n",
    "In doing so, AIA images the very hottest part of the solar atmosphere, around 0.5-4 MK.\n",
    "By analyzing images from AIA as a function of time, we can better understand how plasma in the solar atmosphere is heated.\n",
    "\n",
    "In this notebook, we will show how to perform a *time-lag analysis* between two wavelengths over the course of a 12 h observing window in order to better understand how the solar coronal plasma is evolving around 1 MK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a05b16-79f0-42b2-8e38-ec40ccb8ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import astropy.units as u\n",
    "import astropy.io.fits\n",
    "import astropy.time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.visualization import ImageNormalize, AsinhStretch\n",
    "from reproject import reproject_adaptive\n",
    "import sunpy.map\n",
    "import sunpy.util\n",
    "from sunpy.net import Fido, attrs as a\n",
    "from sunpy.coordinates import propagate_with_solar_surface\n",
    "import ndcube\n",
    "from sunkit_image.time_lag import time_lag\n",
    "\n",
    "from dask_gateway import Gateway\n",
    "from dask.distributed import PipInstall\n",
    "import dask.array\n",
    "\n",
    "from net.heliocloud import HelioCloudClient\n",
    "import net.attrs as heliocloud_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81096305-e5e1-4e01-bc17-7f9a13ebda74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8399f4-0a55-4f1c-93d3-37d65f247cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = Gateway()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48413615-163a-4820-b084-056cd00581e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = gateway.cluster_options()\n",
    "options.worker_cores = 1\n",
    "options.worker_memory = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce62799-36d1-4e1d-ab7d-7e78d525e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = gateway.new_cluster(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c95f9-e85a-4425-ac12-c6f9d8acaf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c5d5c-65bd-4915-9d4d-2e65d37efd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_plugin = PipInstall(\n",
    "    packages=[\n",
    "        \"ndcube\",\n",
    "        \"sunpy[map]\",\n",
    "        \"astropy\",\n",
    "    ],\n",
    "    pip_options=[\"--upgrade\"],\n",
    ")\n",
    "client.register_worker_plugin(pip_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7ac98-fc06-4703-93bd-ba33dedb5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(minimum=3, maximum=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f558b51-4a9f-4192-9754-c7c4f1bc26b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Searching for data\n",
    "\n",
    "First, define the wavelengths we want to search over and the time range.\n",
    "We have identified the time interval of interest using the active region on the Sun that we want to study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f617b-a81a-4e5d-b22b-e93a5f9c8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 12*u.h\n",
    "midpoint = astropy.time.Time('2018-05-29 18:00:00', scale='utc')\n",
    "time_start = midpoint-interval/2\n",
    "time_end = midpoint+interval/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710affb-2901-43bc-b2c5-c2657b941c6c",
   "metadata": {},
   "source": [
    "To search for data, we can use the `Fido` search interface provided by `sunpy` combined with a custom client developed to search the HelioCloud database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807e911-e6b8-443d-9a73-95c69101c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Fido.search(\n",
    "    a.Time(time_start, time_end),\n",
    "    a.Wavelength(171*u.angstrom),\n",
    "    heliocloud_attrs.Dataset('AIA'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992500d9-82a2-4b45-a156-92c6129803ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3b9fa-6c5e-4fa4-bcee-0589bc0fc53c",
   "metadata": {},
   "source": [
    "Rather than return a list of files for us to download, our search just returns us a list of S3 URLs that we can use to directly load our data from.\n",
    "No downloading required!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7313010-90ee-4231-8fbc-27a8209c44e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Identifying the Active Region\n",
    "\n",
    "Next, we need to identify where our active region is on the disk.\n",
    "We do this at a specific time that is approximately the midpoint of our observing interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44f5b3-6872-41a3-b620-5d33c7a7878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_midpoint = np.argmin(np.fabs((astropy.time.Time(q[0]['Start time']) - midpoint).to_value('s')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4808c84-db9d-4323-9a20-f3821f7d07ca",
   "metadata": {},
   "source": [
    "We can then load in our full-disk map at that time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f67ed8-fab8-4e50-a312-26fc3e393fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with astropy.io.fits.open(q[0]['URL'][i_midpoint], use_fsspec=True, fsspec_kwargs={'anon': True}) as hdul:\n",
    "    header = hdul[1].header\n",
    "    data = hdul[1].data\n",
    "ref_map_full_disk = sunpy.map.Map(data, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06339b47-c973-483b-8afb-abddb1884916",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_map_full_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa83c20-a9af-4abd-93fc-b8e08a6b8f1e",
   "metadata": {},
   "source": [
    "Let's identify the active region we are interested in.\n",
    "This is an area of intense magnetic activity where the plasma trapped along magnetic field lines is heating and cooling.\n",
    "We can visually locate the center of this region and a surrounding field of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3a3b8-1d2e-4261-96d2-2c7bc9daab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_center = SkyCoord(Tx=-125*u.arcsec, Ty=250*u.arcsec, frame=ref_map_full_disk.coordinate_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca826f-177d-4684-a1e3-621d829740c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fov = (500, 500)*u.arcsec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31c8c3-2358-49b1-872b-e3e910b7b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_left = SkyCoord(Tx=ar_center.Tx-fov[0]/2,\n",
    "                       Ty=ar_center.Ty-fov[1]/2,\n",
    "                       frame=ref_map_full_disk.coordinate_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c25e07-4736-4054-9861-a47f5a8cc06d",
   "metadata": {},
   "source": [
    "The blue cross indicates the center of the active region.\n",
    "The white box represents the bounding box that denotes our entire region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ddbc0-9eba-42ae-a459-73c181604db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(projection=ref_map_full_disk)\n",
    "ref_map_full_disk.plot(axes=ax)\n",
    "ref_map_full_disk.draw_quadrangle(bottom_left, width=fov[0], height=fov[1])\n",
    "ax.plot_coord(ar_center, marker='X', color='C0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e7771-a5f8-4186-a1a1-e8a1f2ff3283",
   "metadata": {},
   "source": [
    "We can now use these coordinates to create a cutout of submap from our larger full-disk map as we are only interested in studying a small region of the original map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcedc3b8-b273-41ad-81c0-7454ef385b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_map_cutout = ref_map_full_disk.submap(bottom_left, width=fov[0], height=fov[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b227a4-b1e6-4ba7-a9b2-59bf38b2f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_map_cutout.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72769d-954c-4a2d-a526-84687ea16dc8",
   "metadata": {},
   "source": [
    "## Loading Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a993f63-bf89-44c0-8e84-17293bd8ac0d",
   "metadata": {},
   "source": [
    "Now that we know what our region of interest is, we want to select the image data corresponding to that region of interest at each timestep using the URLs returned by our search.\n",
    "To do this, we need to first build a Map for each file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293cba0-991d-496f-a6b2-98b62f898c46",
   "metadata": {},
   "source": [
    "At its core, a map is just a data array plus a metata object.\n",
    "To build a map, we require the metadata of each map to be in memory.\n",
    "\n",
    "We'll define a function that just returns the header from each file and returns this to the RAM of our notebook environment.\n",
    "The memory footprint of this is very small and fast to load so doing this eagerly is not an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e6f56-28b2-4b1a-8de2-2566e6f968c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header(filename):\n",
    "    with astropy.io.fits.open(filename, use_fsspec=True, fsspec_kwargs={'anon': True}, lazy_load_hdus=True) as hdul:\n",
    "        header = hdul[1].header\n",
    "    return astropy.io.fits.Header(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903399f-7d38-49d1-8463-0cf30c32c09b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_headers = client.gather(client.map(get_header, q[0]['URL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a707c9b-1615-4116-bb5e-9e94c0cc07ca",
   "metadata": {},
   "source": [
    "## Building the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab67483-2681-4919-8b32-e10b78f06a1b",
   "metadata": {},
   "source": [
    "The data arrays, on the other hand, need to be loaded lazily as Dask arrays.\n",
    "These are 5K by 5K arrays.\n",
    "Let's first define a delayed function that returns the data array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4fbf9c-27dd-4626-b2d9-e1ea3305074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def get_data(filename):\n",
    "    with astropy.io.fits.open(filename, use_fsspec=True, fsspec_kwargs={'anon': True}) as hdul:\n",
    "        data = hdul[1].data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03eb2c-55f5-46b9-9316-580636938f3f",
   "metadata": {},
   "source": [
    "Fortunately, our map object works well with Dask arrays so we can just create a Dask array from our delayed object and build all of our maps lazily using just our headers and list of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d752a8b-4fea-4113-8688-bff15b1e1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_from_delayed(delayed_array, header, dtype):\n",
    "    shape = (header['NAXIS2'], header['NAXIS1'])\n",
    "    array = dask.array.from_delayed(delayed_array, shape, dtype=dtype,)\n",
    "    return sunpy.map.Map(array, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401178f-d68a-4cc0-b3fe-d30d402271a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_disk_maps = [map_from_delayed(get_data(f), h, ref_map_full_disk.data.dtype) for f, h in zip(q[0]['URL'], all_headers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d155cea-936d-43c3-99c9-39d2bb64a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_disk_maps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6f6b17-0c6d-4c14-8880-1a665f06546c",
   "metadata": {},
   "source": [
    "## Exposure Time Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ce789-5b99-4d0c-94a4-d8ff9abd2488",
   "metadata": {},
   "source": [
    "Each time the telescope records an image, the shutter is left open for some amount of time known as the exposure time.\n",
    "This value is stored in metadata of the map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d97e2-6fa7-4a78-a1dd-c48865fef594",
   "metadata": {},
   "source": [
    "In general, this amount can vary from one image to the next so we must normalize each individual image according to that exposure time.\n",
    "This is just a matter of dividing each image through by the exposure time which gives us back a new map whose data is now normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef5003-6274-4071-9c02-8a51cb4f589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_maps = [sunpy.map.Map(m.data/m.exposure_time.to_value('s'), m.meta) for m in full_disk_maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd8135-b7ed-4926-b51c-bce16cc86c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_maps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021d497-1944-4cb9-bf06-c90d87d6514a",
   "metadata": {},
   "source": [
    "## Aligning and Selecting FOV with Reprojection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f3b46-baec-40c7-a33a-58c3ff50dba2",
   "metadata": {},
   "source": [
    "Due to the rotation of the Sun, the active region rotates across the field of view of SDO (approximately located at Earth).\n",
    "Thus, we must account for this rotation when selecting our region of interest from the full-disk maps.\n",
    "We do this by *reprojecting* each image to the field of view of our cutout region that we initially selected at the midpoint of our observing interval.\n",
    "This has the effect of rotating our region of interest appropriately either forward or backward in time.\n",
    "\n",
    "All of this can be accomplished using the `reproject` package, an Astropy-affiliated package, combined with `sunpy.coordinates` to properly account for the differential rotation of the Sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82baefe-5304-4f6c-8fcc-936b0ef5e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def reproject_array(input_array, input_wcs, target_wcs):\n",
    "    with propagate_with_solar_surface():\n",
    "        out_array = reproject_adaptive((input_array, input_wcs),\n",
    "                                       target_wcs,\n",
    "                                       shape_out=target_wcs.array_shape,\n",
    "                                       roundtrip_coords=False,\n",
    "                                       return_footprint=False)\n",
    "    return out_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbd3de-93a4-484a-9573-90163bbaa7fe",
   "metadata": {},
   "source": [
    "As before, we can build a Dask array from this delayed function and build a list of our reprojected maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816f908-0579-498e-baec-f70259484157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_map(input_map, target_wcs):\n",
    "    delayed_array = reproject_array(input_map.data, input_map.wcs, target_wcs)\n",
    "    target_header = target_wcs.to_header()\n",
    "    target_header['NAXIS1'] = target_wcs.array_shape[1]\n",
    "    target_header['NAXIS2'] = target_wcs.array_shape[0]\n",
    "    return map_from_delayed(delayed_array, target_header, input_map.data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c88f19-a9ee-443d-bf22-20afeca82d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprojected_maps = [reproject_map(m, ref_map_cutout.wcs) for m in normalized_maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcec62d-0925-4e9c-bde2-e20960aef2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprojected_maps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe6e5dc-ec20-407b-8aa9-d1da876ad6b8",
   "metadata": {},
   "source": [
    "Note that if we look at the first and last maps in our list, we see that both remain in the center of our field of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769c2d8-f01a-4eb0-9138-8bb943b111ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprojected_maps[0].peek(**ref_map_cutout.plot_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993558be-31bd-4905-8b1f-d5d50f2e6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprojected_maps[-1].peek(**ref_map_cutout.plot_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268d16e-bf40-4ec7-b5ba-b0211010e188",
   "metadata": {},
   "source": [
    "## Stacking Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7acc4-80f7-4cad-bd3a-d00ee8b646c1",
   "metadata": {},
   "source": [
    "Finally, we want to stack all of these aligned images into a single data cube.\n",
    "Let's define a function that stacks all of our aligned cutouts together, interpolates them to a common time axis, and then returns an `NDCube` object.\n",
    "The SunPy-affiliated `ndcube` package provides data structures for handling $N$-dimensional datacubes with an associated WCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2397d5b-73a7-4562-aaae-ace4abb68340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_and_interpolate(cutouts, time_cutouts, time_common):\n",
    "    # Stack data\n",
    "    data_stacked = np.stack([c.data for c in cutouts], axis=0)\n",
    "    # Rechunk along time axis\n",
    "    data_stacked = data_stacked.rechunk(chunks=data_stacked.shape[:1]+(300, 300))\n",
    "    # Interpolate to common time\n",
    "    f_interp = lambda y: interp1d(time_cutouts.to_value('s'), y, axis=0, kind='linear', fill_value='extrapolate')\n",
    "    data_interp = dask.array.map_blocks(\n",
    "        f_interp(time_common.to_value('s')),\n",
    "        data_stacked,\n",
    "        chunks=time_common.shape+data_stacked.chunks[1:],\n",
    "        dtype=data_stacked.dtype\n",
    "    )\n",
    "    # Add the time axis to our coordinate system\n",
    "    combined_wcs = cutouts[0].wcs.to_header()\n",
    "    combined_wcs['CTYPE3'] = 'TIME'\n",
    "    combined_wcs['CUNIT3'] = 's'\n",
    "    combined_wcs['CDELT3'] = np.diff(time_common)[0].to_value('s')\n",
    "    combined_wcs['CRPIX3'] = 1\n",
    "    combined_wcs['CRVAL3'] = time_common[0].to_value('s')\n",
    "    combined_wcs = astropy.wcs.WCS(combined_wcs)\n",
    "\n",
    "    return ndcube.NDCube(data_interp, wcs=combined_wcs, unit=cutouts[0].unit, meta=cutouts[0].meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2766e6d-19af-494e-8126-bb39ad92943e",
   "metadata": {},
   "source": [
    "Because each filter of the AIA telescope does not take an observation at exactly the same time, we need to interpolate each data cube corresponding each channel to a common time array.\n",
    "This common time array will be shared across all wavelengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340e4b3-bad9-4803-a5d7-9398c676de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadence = 4*u.min\n",
    "delta_time = time_end - time_start\n",
    "time_common = time_start + np.arange(0, delta_time.to_value('s'), cadence.to_value('s')) * u.s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f601a6-4002-4632-a74d-9ce65a4251d0",
   "metadata": {},
   "source": [
    "We can extract the time of each map from the map metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9a68a-4623-4278-8c6c-29c8bab21eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_171 = astropy.time.Time([m.date for m in normalized_maps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02fd245-aef9-4336-bf74-51844ffe285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_171 = stack_and_interpolate(reprojected_maps,\n",
    "                                     (time_171 - time_common[0]).to('s'),\n",
    "                                     (time_common-time_common[0]).to('s'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadc698-b62c-49da-a976-9c56fb15ac3b",
   "metadata": {},
   "source": [
    "Note that the stacked datacube is a Dask array with chunks oriented along the time axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd19667-6b36-410b-a75a-35447e0c0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_171.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8171b-84d0-4864-9d02-ba4200cfb267",
   "metadata": {},
   "source": [
    "Slicing our NDCube yields still another NDCube, still backed by a Dask array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8af21-269a-4a04-9355-503bb4742a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_cube = cube_171[:,400:600,400:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a05d1-b89a-424f-870a-4b9fe40a5c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14b2f3f-bcec-4a63-8a62-3a8553d24497",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_cube.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61520ffe-dfec-42cd-b925-1aa239e571c5",
   "metadata": {},
   "source": [
    "Operations on the cube still preserve \"laziness\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3358c-2df4-4723-8537-9473230620dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_averaged = sliced_cube.rebin((1, 200, 200), operation=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0b97d-f3d4-4092-9605-61e4dee58125",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd917e3-3625-4169-a09a-b1e2945ca0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_averaged.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01951e4-aad4-4d44-8f63-6debfb618f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_averaged[:,0,0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfaeeb-1ccd-4594-a174-6ea7d6c9b301",
   "metadata": {},
   "source": [
    "## Now do this for another channel..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338a4b8-c80b-4420-b24c-f7f40137c8ba",
   "metadata": {},
   "source": [
    "We now want to carry out all of these steps for another wavelength imaged by AIA: 193 Å. \n",
    "This channel is most sensitive to plasma around 2 MK.\n",
    "\n",
    "To make this a bit easier, let's combine all of these steps we went through above into a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b5dc3-5eef-4272-96c2-de0898ee2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cutout_cube(file_urls, time_common, ref_map):\n",
    "    all_headers = client.gather(client.map(get_header, file_urls))\n",
    "    full_disk_maps = [map_from_delayed(get_data(f), h, np.int32) for f,h in zip(file_urls, all_headers)]\n",
    "    normalized_maps =[sunpy.map.Map(m.data/m.exposure_time.to_value('s'), m.meta) for m in full_disk_maps]\n",
    "    reprojected_maps = [reproject_map(m, ref_map.wcs) for m in normalized_maps]\n",
    "    time_maps = astropy.time.Time([m.date for m in normalized_maps])\n",
    "    cube = stack_and_interpolate(reprojected_maps,\n",
    "                                 (time_maps - time_common[0]).to('s'),\n",
    "                                 (time_common-time_common[0]).to('s'))\n",
    "    return cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212d99e-bac1-46e4-a92c-bd574c66aca6",
   "metadata": {},
   "source": [
    "Now, let's search for all 193 Å images in the same interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16a2c9-03a7-4557-be40-ea7abce945ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_193 = Fido.search(\n",
    "    a.Time(time_start, time_end),\n",
    "    a.Wavelength(193*u.angstrom),\n",
    "    heliocloud_attrs.Dataset('AIA'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a9b69e-f77d-4c64-be94-ab0994b1a6dc",
   "metadata": {},
   "source": [
    "And use them to build a datacube for this wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87347b2c-d087-458d-9196-e8ba291a24b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cube_193 = build_cutout_cube(q_193[0]['URL'], time_common, ref_map_cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e7bca-2a4e-4697-81af-73e13af8cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_193.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d792412f-54ca-483b-a4da-1e59cf5dfc0a",
   "metadata": {},
   "source": [
    "## Time Lag Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ca1e2-c2ba-4be3-bb5a-ff598363d625",
   "metadata": {},
   "source": [
    "We now have a datacube for the entire active region as a function of time for both the 171 and 193 Å wavelengths on the same spatial and temporal grid.\n",
    "Because these wavelengths are sensitive to plasma at very different temperatures, by analyzing how the intensity evolves in time in each channel, we can start to understand the thermodynamics of the solar atmosphere.\n",
    "\n",
    "One way to do that is through a cross-correlation analysis.\n",
    "The cross-correlation between two timeseries $A$ and $B$ is defined as,\n",
    "\n",
    "$$\n",
    "\\mathcal{C}_{AB}(\\tau) = \\mathcal{F}^{-1}\\left\\{\\mathcal{F}\\{I_A(-t)\\}\\mathcal{F}\\{I_B(t)\\}\\right\\}\n",
    "$$\n",
    "\n",
    "where $\\tau$ is the temporal offset between the two signals.\n",
    "The *time lag* is the temporal offset that maximizes the cross-correlation between the two signals,\n",
    "\n",
    "$$\n",
    "\\tau_{AB} = \\arg\\max_\\tau\\mathcal{C}_{AB}(\\tau)\n",
    "$$\n",
    "\n",
    "The time lag between the 193 Å and 171 Å wavelengths then provides a proxy for how long it takes the plasma to cool from 2 MK to 1 MK.\n",
    "Computing this in every pixel then gives us a map of the cooling plasma over the entire active region!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318098ef-8e22-4bd5-9079-b664f5fa72ff",
   "metadata": {},
   "source": [
    "Fortunately, this calculation is already implemented in a Dask-friendly way in the SunPy-affiliated `sunkit-image` package which means that we can just pass our aligned arrays as Dask datacubes and this calculation will be added to our task graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14413577-538f-41c5-90d5-5efed9e5d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_193_171 = time_lag(cube_193.data, cube_171.data, (time_common-time_common[0]).to('s'), [-6,6]*u.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4d933-f4a7-4b33-9312-100336d31d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_193_171"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25275693-6690-492b-8cc1-0f1e38c2ed1b",
   "metadata": {},
   "source": [
    "Finally. let's visualize this map of cooling plasma!\n",
    "By plotting it in matplotlib, we kick off the computation of our graph, starting all the way from our unprocessed data to our final science result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49427cc3-d9a6-4429-b5d5-0e4dc3d0d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_map = ndcube.NDCube(tl_193_171, wcs=ref_map_cutout.wcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210dce0-3365-4e16-8f0f-6f792c3e3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "tl_map.plot(cmap='RdYlBu_r', vmin=-7200, vmax=7200)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b4018-b9c8-4cfb-b9c2-e02f7c0440ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scipy-2023-talk]",
   "language": "python",
   "name": "conda-env-scipy-2023-talk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
